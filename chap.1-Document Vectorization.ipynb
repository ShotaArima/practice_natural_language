{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShotaArima/practice_natural_language/blob/main/chap.1-Document%20Vectorization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 第1章 文書のベクトル化"
      ],
      "metadata": {
        "id": "USEkWJ7hFUQF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## janomeによる単語分割"
      ],
      "metadata": {
        "id": "2EyHduCEFfJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install janome"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXNfbxBCEYvw",
        "outputId": "e72ab1cd-05fa-4c54-daa0-1c2a9fa6bdc3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting janome\n",
            "  Downloading Janome-0.5.0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Downloading Janome-0.5.0-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: janome\n",
            "Successfully installed janome-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import janome\n",
        "from janome.tokenizer import Tokenizer"
      ],
      "metadata": {
        "id": "l3kB5m4B1J0J"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = Tokenizer()"
      ],
      "metadata": {
        "id": "sZvdKVKiEM4I"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in t.tokenize('私は秋田犬が大好きです。'):\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8bhuXfyFm0q",
        "outputId": "7b435b97-1789-48a8-8aa7-75a8c0db0043"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "私\t名詞,代名詞,一般,*,*,*,私,ワタシ,ワタシ\n",
            "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
            "秋田\t名詞,固有名詞,地域,一般,*,*,秋田,アキタ,アキタ\n",
            "犬\t名詞,一般,*,*,*,*,犬,イヌ,イヌ\n",
            "が\t助詞,格助詞,一般,*,*,*,が,ガ,ガ\n",
            "大好き\t名詞,形容動詞語幹,*,*,*,*,大好き,ダイスキ,ダイスキ\n",
            "です\t助動詞,*,*,*,特殊・デス,基本形,です,デス,デス\n",
            "。\t記号,句点,*,*,*,*,。,。,。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wakati=Trueで分かち書きモード\n",
        "for token in t.tokenize('私は秋田犬が大好きです。', wakati=True):\n",
        "  print(token, end='/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpIEgY79F19i",
        "outputId": "6012c143-2901-435a-a376-254380186e74"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "私/は/秋田/犬/が/大好き/です/。/"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 半角スペースで分割\n",
        "for token in t.tokenize('私は秋田犬が大好きです。', wakati=True):\n",
        "  print(token, end=' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oH0oxKabGtid",
        "outputId": "c8fda3a4-9337-4a6e-9850-513fd48c4ab0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "私 は 秋田 犬 が 大好き です 。 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# リストに格納\n",
        "words = [token for token in t.tokenize('私は秋田犬が好きです。', wakati=True)]\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pu_QQBgHU2y",
        "outputId": "d3749dda-ee07-4689-8e78-8e3bc1c8bfcb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['私', 'は', '秋田', '犬', 'が', '好き', 'です', '。']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## N-gram"
      ],
      "metadata": {
        "id": "-UVxhpBNPDNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# bi-gram\n",
        "for i in range (len(words)-1):\n",
        "    print(f\"{i}:{words[i:i+2]}\")"
      ],
      "metadata": {
        "id": "3fBbBogOH01a",
        "outputId": "7295c91d-47ad-49bd-ad15-0c47a8944b9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:['私', 'は']\n",
            "1:['は', '秋田']\n",
            "2:['秋田', '犬']\n",
            "3:['犬', 'が']\n",
            "4:['が', '好き']\n",
            "5:['好き', 'です']\n",
            "6:['です', '。']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# n-gram\n",
        "def get_word_n_grams(sentence, n):\n",
        "    words = [token for token in t.tokenize(sentence, wakati=True)]\n",
        "    result = []\n",
        "    for index in range(len(words)):\n",
        "        result.append(words[index: index+n])\n",
        "        if index+n >= len(words):\n",
        "            return result"
      ],
      "metadata": {
        "id": "BpT7FtHwPMT6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = 'すもももももももものうち'\n",
        "print(get_word_n_grams(input, 3))"
      ],
      "metadata": {
        "id": "GyUk0jJzQh5z",
        "outputId": "92961a8e-4a26-4d47-fad7-ca089ac5d79e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['すもも', 'も', 'もも'], ['も', 'もも', 'も'], ['もも', 'も', 'もも'], ['も', 'もも', 'の'], ['もも', 'の', 'うち']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 文字のN-gram"
      ],
      "metadata": {
        "id": "a1zRT4x0RvcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_charactor_n_gram(sentence, n):\n",
        "    result = []\n",
        "    for index in range(len(sentence)):\n",
        "        result.append(sentence[index: index+n])\n",
        "        if index+n >= len(sentence):\n",
        "            return result"
      ],
      "metadata": {
        "id": "MV9K0UYJQvLs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input2 = '私は秋田犬が大好きだ。'\n",
        "print(get_charactor_n_gram(input2, 2))"
      ],
      "metadata": {
        "id": "8j3A4EYKSJSU",
        "outputId": "9dc2a35b-f994-4ead-ed2a-d74b1781b3a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['私は', 'は秋', '秋田', '田犬', '犬が', 'が大', '大好', '好き', 'きだ', 'だ。']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bag-of-words"
      ],
      "metadata": {
        "id": "FBXV9I0jnH5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(sentence):\n",
        "    return [token for token in t.tokenize(sentence, wakati=True)]"
      ],
      "metadata": {
        "id": "Lwr1276ESXwk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words1 = '私は秋田犬が大好き。'\n",
        "words2 = '私は犬が少し苦手。'\n",
        "\n",
        "print(f\"words1:{tokenize(words1)}\")\n",
        "print(f\"words2:{tokenize(words2)}\")"
      ],
      "metadata": {
        "id": "aUH18EaMnUef",
        "outputId": "f35b480b-243d-49ed-a054-e0f37e82d20d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "words1:['私', 'は', '秋田', '犬', 'が', '大好き', '。']\n",
            "words2:['私', 'は', '犬', 'が', '少し', '苦手', '。']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 文書ベクトルの作成\n",
        "def get_bag_of_words(document):\n",
        "    result_dict = {}\n",
        "    words = tokenize(document)\n",
        "    for word in words:\n",
        "        if word not in result_dict:\n",
        "            result_dict[word] = 1\n",
        "        else:\n",
        "            result_dict[word] += 1\n",
        "    return result_dict"
      ],
      "metadata": {
        "id": "FUv5S_J2ntwo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document1 = '私は秋田犬が大好き。秋田犬は私が大好き。'\n",
        "document2 = '私は犬が少し苦手。'\n",
        "print(f\"document1:{get_bag_of_words(document1)}\")\n",
        "print(f\"document2:{get_bag_of_words(document2)}\")"
      ],
      "metadata": {
        "id": "y3WKy5ZEppGb",
        "outputId": "e28107aa-f0ea-4111-ad11-3516ef00d563",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "document1:{'私': 2, 'は': 2, '秋田': 2, '犬': 2, 'が': 2, '大好き': 2, '。': 2}\n",
            "document2:{'私': 1, 'は': 1, '犬': 1, 'が': 1, '少し': 1, '苦手': 1, '。': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 辞書\n",
        "def make_dictinary(documents):\n",
        "    result_dict = {}\n",
        "    index = 1\n",
        "    for doc in documents:\n",
        "        words = tokenize(doc)\n",
        "        for word in words:\n",
        "            if word not in result_dict:\n",
        "                result_dict[word] = index\n",
        "                index+=1\n",
        "    return result_dict"
      ],
      "metadata": {
        "id": "0P316AEHp_I5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [document1, document2]\n",
        "dictionary = make_dictinary(documents)\n",
        "print(f\"dict:{dict}\")"
      ],
      "metadata": {
        "id": "jFeG0ZEisI14",
        "outputId": "fe121033-f19a-467d-8f64-26afc5b39bc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict:<class 'dict'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 用例ベクトルの作成\n",
        "def make_BOW_vectors(documents, dictionary):\n",
        "    result_vectors = []\n",
        "    for doc in documents:\n",
        "        vec = {}\n",
        "        words = tokenize(doc)\n",
        "        for entry in dictionary:\n",
        "            vec[dictionary[entry]]=0\n",
        "        for word in words:\n",
        "            vec[dictionary[word]] += 1\n",
        "        result_vectors.append(vec)\n",
        "    return result_vectors"
      ],
      "metadata": {
        "id": "xu71RG3psaZh"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectors = make_BOW_vectors(documents, dictionary)\n",
        "print(f\"結果:{vectors}\")\n",
        "\n",
        "id_to_word = {v: k for k, v in dictionary.items()} # 辞書型を逆変換する\n",
        "word_occurrences = []\n",
        "for occurrence in vectors:\n",
        "    word_dict = {}\n",
        "    for id_num, count in occurrence.items():\n",
        "        word = id_to_word[id_num]\n",
        "        word_dict[word] = count\n",
        "    word_occurrences.append(word_dict)\n",
        "for occurrences in word_occurrences:\n",
        "    print(f\"結果:{occurrences}\")"
      ],
      "metadata": {
        "id": "k50KEnwMtufs",
        "outputId": "cb1de201-ead0-4a02-8eca-9750cd266e4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "結果:[{1: 2, 2: 2, 3: 2, 4: 2, 5: 2, 6: 2, 7: 2, 8: 0, 9: 0}, {1: 1, 2: 1, 3: 0, 4: 1, 5: 1, 6: 0, 7: 1, 8: 1, 9: 1}]\n",
            "結果:{'私': 2, 'は': 2, '秋田': 2, '犬': 2, 'が': 2, '大好き': 2, '。': 2, '少し': 0, '苦手': 0}\n",
            "結果:{'私': 1, 'は': 1, '秋田': 0, '犬': 1, 'が': 1, '大好き': 0, '。': 1, '少し': 1, '苦手': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CountVectorizerモジュール\n",
        "- scikit-learnのモジュール"
      ],
      "metadata": {
        "id": "K2FIpU4ZQqQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# wakatiを使用して単語間に半角スペースを入れる\n",
        "def make_corps(documents):\n",
        "    result_corps = []\n",
        "    for doc in documents:\n",
        "        words = tokenize(doc)\n",
        "        text=\" \".join(words)\n",
        "        result_corps.append(text)\n",
        "    return result_corps"
      ],
      "metadata": {
        "id": "B-Ymke3quyuK"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t  = Tokenizer()\n",
        "document1 = '私は秋田犬が大好き。秋田犬は私が大好き。'\n",
        "document2 = '私は犬が少し苦手。'\n",
        "documents = [document1, document2]\n",
        "corpuses = make_corps(documents)\n",
        "for corpus in corpuses:\n",
        "    print(corpus)"
      ],
      "metadata": {
        "id": "9KTbAdg5Rms0",
        "outputId": "71fa7ef4-13e8-48da-f0ba-aabc12a5c06f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "私 は 秋田 犬 が 大好き 。 秋田 犬 は 私 が 大好き 。\n",
            "私 は 犬 が 少し 苦手 。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CountVectorizerを使用する\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "1wMueIImSlnj"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(token_pattern='(?u)\\\\b\\\\w+\\\\b')\n",
        "X = vectorizer.fit_transform(corpuses)\n",
        "print(vectorizer.get_feature_names_out(corpuses))"
      ],
      "metadata": {
        "id": "QdSJHk24UbkO",
        "outputId": "ae1165c3-20e3-4c6b-a3e1-beff430d5c82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['が' 'は' '大好き' '少し' '犬' '私' '秋田' '苦手']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.toarray())"
      ],
      "metadata": {
        "id": "v45TNqhXVQ_n",
        "outputId": "1cfd5ce6-6a98-4e0f-c68f-e90adee6719a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2 2 2 0 2 2 2 0]\n",
            " [1 1 0 1 1 1 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sTQoWfyNVUa9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}